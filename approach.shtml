---
layout: default
title: About Our Approach
---

<P>
CHTC supports a variety of computation modes, but our specialty is
 High <i>Throughput</i> Computing (HTC), which involves
 breaking up a single large computational task into many smaller tasks for
 the fastest overall turnaround. Importantly, most of our users find HTC to be
 a more helpful approach in accelerating their computational work and their
 research. 
To this end, we support thousands of multi-core computers and use task
 scheduling software called HTCondor, developed right here in Madison, to run thousands of
independent jobs on as many total processors as possible that can all be shared between groups of users.
These computers, or "machines", are distributed across several collections that we call <i>pools</i> (similar to "clusters"). 
</br></br>
The diagram below shows some of the largest pools on campus and also shows
 our connection to the US-wide Open Science Grid where UW computing work
 can "backfill" available computers all over the country. The number under
 each resource name shows an approximate number of computing hours available to campus researchers for a typical week in Fall 2013. As demonstrated in the diagram, 
we help users to submit their work not only to our CHTC-owned machines, but to improve their throughput even further by seamlessly accessing 
as many available computers as possible, all over campus <i>AND</i> all over the country.
</br></br>
The vast majority of the computational work that campus researcher have is HTC, though we
 are happy to support researchers with a variety of beyond-the-desktop needs, including
 tightly-coupled computations (e.g. MPI) and high-memory work (e.g. metagenomics), as well
 as specialized hardware like GPUs.
<P>
<img src="/includes/chtc-pools.png" height="440" width="513" style = "float:right; margin:20px; margin-right:0;"/>
<p>
<b>What kinds of applications run best in the CHTC?</b>
<p>
"Pleasantly parallel" computational work (in which each of <i>many</i> jobs can run independently) work best in the CHTC, and
 we can offer the greatest computational capacity for this type of work. Analyzing thousands of images, inferring statistical significance of hundreds of thousands of samples, optimizing an electric motor
design with millions of constraints, aligning genomes, and performing deep linguistic search on a 30 TB sample of the internet
are a few of the applications that campus researchers run every day in the CHTC.  If you are not sure if your application is a good fit
for CHTC resources, <a href="chtc@cs.wisc.edu">get in touch</a> and we will be happy to help you figure it out. </p>
Within a single compute system, we also support GPUs, high-memory servers, and specialized hardware owned by individual research 
groups. For tightly-coupled computationa (e.g. MPI and similar programmed parallelization), our resources include an HPC Cluster, with 
faster inter-node networking.
<p>
<b>How to get access.</b>
<p>
While you may be excited at the prospect of harnessing 100,000 compute hours a day for your research, the most valuable
thing we offer is, well, us.  We have a small, yet dedicated team of professionals who eat, breathe and sleep distributed computing.
Simply <a href="get-started.shtml">request an account</a>, and one of our dedicated Research Computing Facilitators will follow 
up to provide specific recommendations to accelerate YOUR science.
<P>
