---
highlighter: none
layout: guide
title: Citing CHTC Resources
---


In a Publication
----------------

In order to track our scientific impact we ask that users cite the following DOI in all publications
that have benefited from our services.

> [https://doi.org/10.21231/GNT1-HW21](https://doi.org/10.21231/GNT1-HW21)

(Last updated Feb, 2023)

[Appropriate acknowledgement of OSG resources is described here](https://osg-htc.org/acknowledging)
  
<br>

For a Grant Proposal
--------------------

(Feel free to modify the below text, use only certain paragraphs, or contact us for more input or customizable letters of support.)

The University of Wisconsin-Madison (UW-Madison) campus is an excellent match for meeting the computational needs of this project. Existing UW-Madison technology infrastructure supported by the CHTC can be readily leveraged, including CPU capacity, network connectivity, storage availability, and middleware connectivity. The UW-Madison has invested in the CHTC as the primary provider of shared, computing resources to campus researchers. All standard CHTC services are provided free-of-charge to UW-Madison researchers, their projects, and collaborators. But perhaps most important, the UW-Madison has significant staff experience and core competency in deploying, managing, and using computational technology.

The CHTC is home to over 20 full-time staff with a proven track record of making compute middleware work for scientists. Far beyond just being familiar with the deployment and use of such software, UW staff has been intimately involved in its design and implementation. Dedicated Research Computing Facilitators are available to provide training to all CHTC users and are available to consult on computational practices for achieving the best scientific throughput. As always, CHTC will be happy to provide consulting to ensure optimal use of its facilities, and development of robust, reproducible methods for scalable computing.


The UW-Madison maintains multiple compute clusters (including the largest of these operated by CHTC) across campus that are managed using either HTCondor or SLURM with support from CHTC. These clusters are connected by HTCondor technology to share resources with each other and with other institutions around the world via [OSG services](https://osg-htc.org/). Local computing capacity directly enabled by CHTC includes:

- High-Throughput Computing (HTC) resources totaling about 30,000 CPU cores in support of research. Temporary file space for large individual files can support up to hundreds of terabytes of total working data. For single computing runs needing significant memory on a single server, the CHTC maintains several multi-core servers with terabytes of memory.

  - When on-campus resources are fully utilized, CHTC leverages [OSG services](https://osg-htc.org/) to provision additional opportunistic resources from multiple external sites.

- A High-Performance Computing (HPC) cluster consisting of roughly 7,000 tightly coupled cores. Compute nodes have 16 or 20 cores each, and 64 or 128 GB RAM, and are networked with 56 Gbps Infiniband, with access to a shared file system and resources managed via Slurm.

- An origin server where users can make research data available through the [Open Science Data Federation](https://osg-htc.org/services/osdf.html) and an on-campus cache server which allows external jobs to cache files locally.

In the last year, CHTC made possible the use of more than 19,000 core years of computing work for campus researchers, supporting 328 projects across a wide range of research domains. Temporary storage space for large files can support up to hundreds of terabytes of total working data. Should these resources not be sufficient for the project, the CHTC can also engage computing resources from across the campus grid and the [OS Pool](https://osg-htc.org/services/open_science_pool.html), an NSF-supported and expanding alliance of more than 100 universities, national laboratories, scientific collaborations, and software developers.

The UW–Madison network currently comprises a 200Gbps backbone and WAN connectivity with 160Gbps to the Discovery building. The equipment is located on the “Research Backbone Network”, which allows for friction-free (e.g., no middlebox devices such as firewalls on the data path) to the nation’s research and education networks. Redundancy is built into the network and its supporting infrastructure. An equitable funding model assures that network resources are kept current. The UW has been fundamental to the establishment of the Broadband Optical Research Education And Science network (BOREAS). This Regional Optical Network (RON) connects to the CIC OmniPoP in Chicago, providing a high-speed gateway to various research networks, including Internet2, ESNet, CERN, and other global research networks. BOREAS, along with our participation in the Northern Tier Network Consortium, provides various options to connect at very high speeds to research partners with shared or dedicated bandwidth

(Last updated March 23, 2023)
