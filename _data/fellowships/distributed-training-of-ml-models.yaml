title: Distributed training of ML models
type: Software Development
scale: Large
summary: |
  As machine learning models become larger and more complex, the computational needs expand beyond
  single-GPU and single-machine capabilities. This project aims to leverage distributed ML software 
  (e.g. PyTorch elastic) within the HTCondor Software Suite (HTCSS) to utilize CHTC resources in 
  these large computing tasks. Students will develop strategies, software components, and guides 
  to enable researchers to distribute training tasks across multiple GPU nodes within the cluster.
  Students working on this project will develop valuable ML and distributed computing knowledge.